{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"d7988fe3-c50c-4940-a161-dfc77b671ca2\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"d7988fe3-c50c-4940-a161-dfc77b671ca2\");\n",
       "      el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete window._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"d7988fe3-c50c-4940-a161-dfc77b671ca2\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'd7988fe3-c50c-4940-a161-dfc77b671ca2' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"d7988fe3-c50c-4940-a161-dfc77b671ca2\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"d7988fe3-c50c-4940-a161-dfc77b671ca2\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "from sklearn import decomposition\n",
    "\n",
    "import bkcharts\n",
    "import bokeh.io\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "from probe2vec.w2v import word2vec, Word2VecEmbedder\n",
    "from probe2vec.dataset_reader import kmerize_fastq_parse, kmerize_fasta_parse, DatasetReader\n",
    "from probe2vec.embedding_utils import build_index, most_similar, merge_counters, reshape_to_vector\n",
    "from probe2vec.theano_minibatcher import (\n",
    "    TheanoMinibatcher, NoiseContrastiveTheanoMinibatcher\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model file params\n",
    "config_dir = os.path.expanduser('~/projects/embedding/src/config_yamls/embedding_dim_exps/')\n",
    "model_yaml = 'k_8_emb_50.yaml'\n",
    "with open(os.path.join(config_dir, model_yaml)) as f:\n",
    "    params = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the embedder\n",
    "results_dir = os.path.expanduser('~/projects/embedding/results/embedding_size/k_8_emb_50/')\n",
    "data_dir = os.path.abspath(params['data_dir'])\n",
    "selex_files = [os.path.join(data_dir,f) for f in os.listdir(data_dir) if f.endswith(params['file_suffixes'])]\n",
    "os.chdir(os.path.expanduser(\"~/projects/embedding/src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionary from ../results/embedding_size/k_8_emb_50...\n",
      "pruning dictionary to eliminate tokens occuring less than 0 times.\n",
      "dropped  0  tokens in pruning the unigram dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../results/embedding_size/k_8_emb_50'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if \"fastq\" in params['parser']:\n",
    "    parser = kmerize_fastq_parse\n",
    "else:\n",
    "    parser = kmerize_fasta_parse\n",
    "    \n",
    "\n",
    "# load the DatasetReader object from the save dir\n",
    "reader = DatasetReader(files=[], directories=[], skip=[], noise_ratio=15, \n",
    "                      t=1e-5, num_processes=3, \n",
    "                      unigram_dictionary=None, \n",
    "                      min_frequency=0, kernel=[1, 2, 3, \n",
    "                      4, 5, 5, 4, 3, 2, 1], \n",
    "                      load_dictionary_dir=params['save_dir'], \n",
    "                      max_queue_size=0, \n",
    "                      macrobatch_size=20000, \n",
    "                      parse=parser, \n",
    "                      verbose=True, k=params['K'], \n",
    "                      stride=params['stride'])\n",
    "    \n",
    "# load the embedder, DatasetReader objects\n",
    "batch_size = 1000\n",
    "noise_ratio=15\n",
    "num_embedding_dimensions=params['num_embedding_dimensions']\n",
    "full_batch_size = batch_size * (1 + noise_ratio)\n",
    "\n",
    "minibatcher = NoiseContrastiveTheanoMinibatcher(\n",
    "    batch_size=batch_size,\n",
    "    noise_ratio=noise_ratio,\n",
    "    dtype=\"int32\",\n",
    "    num_dims=2\n",
    ")\n",
    "\n",
    "embedder = Word2VecEmbedder(input_var=minibatcher.get_batch(),\n",
    "                            batch_size=full_batch_size,\n",
    "                            vocabulary_size=reader.get_vocab_size(),\n",
    "                            num_embedding_dimensions=num_embedding_dimensions)\n",
    "embedder.load(os.path.join(params['save_dir'],''))\n",
    "params['save_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a random set of probes from a randomly chosen factor, embed, and visualize the probes\n",
    "def sample_from_factor(filename, data_dir, percentage=0.1):\n",
    "    factor = filename.split('/')[-1]\n",
    "    factor = factor.split('_')[0]\n",
    "\n",
    "    tokenized_sentences = kmerize_fasta_parse(filename, **params) \n",
    "    samples = bernoulli.rvs(percentage,size=len(tokenized_sentences)).astype('bool').tolist()\n",
    "\n",
    "    return factor, [s for s,i in zip(tokenized_sentences,samples) if i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zamparol/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:6: DeprecationWarning: This function is deprecated. Please call randint(1, 175 + 1) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "random.shuffle(selex_files)\n",
    "factor, sample_sentences = sample_from_factor(selex_files[0], data_dir)\n",
    "other_sentences = []\n",
    "other_factors = []\n",
    "other_factors_by_kmer = []\n",
    "files_indices = np.random.random_integers(1, len(selex_files) - 1,10).tolist()\n",
    "for i in files_indices:\n",
    "    f, s = sample_from_factor(selex_files[i], data_dir, 0.01)\n",
    "    other_sentences.extend(s)\n",
    "    other_factors.extend([f] * len(s))\n",
    "    other_factors_by_kmer.extend([f] * (len(s) * len(s[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed each of the k-mers from the sample sentences, and the other sentences\n",
    "embedded_samples = []\n",
    "embedded_samples_probe_mean = []\n",
    "for sentence in sample_sentences:\n",
    "    sentence_token_ids = [reader.unigram_dictionary.get_id(token) for token in sentence]\n",
    "    embedded_tokens = [embedder.embed(t) for t in sentence_token_ids]\n",
    "    embedded_samples.append(embedded_tokens)\n",
    "    embedded_sample_probe = np.concatenate(embedded_tokens)\n",
    "    embedded_samples_probe_mean.append(embedded_sample_probe)\n",
    "    \n",
    "embedded_others = []\n",
    "embedded_others_probe_mean = []\n",
    "for sentence in other_sentences:\n",
    "    sentence_token_ids = [reader.unigram_dictionary.get_id(token) for token in sentence]\n",
    "    embedded_tokens = [embedder.embed(t) for t in sentence_token_ids]\n",
    "    embedded_others.append(embedded_tokens)\n",
    "    embedded_others_probe_mean.append(np.concatenate(embedded_tokens).mean(axis=0))\n",
    "    \n",
    "embedded_samples_flat = [val for sublist in embedded_samples for val in sublist]\n",
    "embedded_others_flat = [val for sublist in embedded_others for val in sublist]\n",
    "\n",
    "embedded_samples[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 200)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pack into numpy arrays\n",
    "embedded_samples_array = np.concatenate(embedded_samples_flat)\n",
    "embedded_others_array = np.concatenate(embedded_others_flat)\n",
    "\n",
    "embedded_samples_probes = np.stack(embedded_samples_probe_mean)\n",
    "embedded_others_probes = np.stack(embedded_others_probe_mean)\n",
    "\n",
    "embedded_samples_probes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zamparol/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/zamparol/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# apply PCA transformation to both sets\n",
    "all_pts = np.concatenate([embedded_samples_array,embedded_others_array])\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(all_pts)\n",
    "all_pts_2pcs = pca.transform(all_pts)\n",
    "\n",
    "all_probes = np.concatenate([embedded_samples_probes, embedded_others_probes])\n",
    "pca.fit(all_probes)\n",
    "all_probes_2pcs = pca.transform(all_probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pack into data.frame, plot\n",
    "labels = [factor] * len(embedded_samples_flat)\n",
    "other_labels = other_factors_by_kmer\n",
    "labels.extend(other_labels)\n",
    "d = {'PC1': all_pts_2pcs[:,0], 'PC2': all_pts_2pcs[:,1], 'Factor': labels}\n",
    "my_df = pd.DataFrame(data=d)\n",
    "embedded_kmers_2d = ColumnDataSource(my_df)\n",
    "\n",
    "from bkcharts import Scatter, show\n",
    "kmers_2pcs = Scatter(embedded_kmers_2d, x='PC1', y='PC2', color='Factor', marker='Factor',\n",
    "            title=\"PCA plot for embedded k-mers\", legend=\"top_right\",\n",
    "            xlabel=\"PC1\", ylabel=\"PC2\")\n",
    "kmers_2pcs.title.align = \"center\"\n",
    "\n",
    "\n",
    "boutput_nbk()\n",
    "show(row(kmers_2pcs, p6s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ETS1</td>\n",
       "      <td>-0.220868</td>\n",
       "      <td>0.002667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETS1</td>\n",
       "      <td>-0.198260</td>\n",
       "      <td>-0.006365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ETS1</td>\n",
       "      <td>-0.263253</td>\n",
       "      <td>-0.009109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ETS1</td>\n",
       "      <td>-0.509728</td>\n",
       "      <td>0.011946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETS1</td>\n",
       "      <td>-0.213042</td>\n",
       "      <td>0.020661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Factor       PC1       PC2\n",
       "0   ETS1 -0.220868  0.002667\n",
       "1   ETS1 -0.198260 -0.006365\n",
       "2   ETS1 -0.263253 -0.009109\n",
       "3   ETS1 -0.509728  0.011946\n",
       "4   ETS1 -0.213042  0.020661"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2961"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7400, 200)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2509"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7086 - 4577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
